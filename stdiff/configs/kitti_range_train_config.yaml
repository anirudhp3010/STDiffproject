Env:
    output_dir: '/home/anirudh/STDiffProject/STDiff_ckpts/kitti_range_64x512'
    logger: 'tensorboard'
    resume_ckpt: null
    stdiff_init_ckpt: null
    

Dataset:
    name: 'KITTI_RANGE'
    dir: '/DATA/common/kitti/processed_data'
    phase: 'deploy'
    dev_set_size: null
    batch_size: 2 # Reduced for range images
    num_workers: 3
    num_channels: 1  # Grayscale range images
    image_size: [64, 512]  # Range images: 64 height x 512 width
    num_observed_frames: 3
    num_predict_frames: 3
    test_num_observed_frames: 3
    test_num_predict_frames: 3
    rand_Tp: 3
    rand_predict: True
    half_fps: False
    test_folder_ids: [9]  # Folder indices for testing (sequences 08, 09, 10)

STDiff:
    Diffusion:
        prediction_type: 'epsilon' #'epsilon' or 'sample'
        ddpm_num_steps: 100
        ddpm_num_inference_steps: 50
        ddpm_beta_schedule: 'squaredcos_cap_v2'

        unet_config:
            sample_size: [64, 512]  # Non-square: 64 height x 512 width
            in_channels: 2  # For autoregressive: 1 (current) + 1 (previous frame)
            out_channels: 1  # Grayscale output
            m_channels: 256
            layers_per_block: 2
            #config for resolution 64x512
            block_out_channels: [128, 256, 512, 768, 1024]
            down_block_types: ["DownBlock2D","AttnDownBlock2D","AttnDownBlock2D", "AttnDownBlock2D", "AttnDownBlock2D"]
            up_block_types: ["AttnUpBlock2D", "AttnUpBlock2D","AttnUpBlock2D", "AttnUpBlock2D", "UpBlock2D"]
            attention_head_dim: [null, 32, 64, 192, 256]

    DiffNet:
        autoregressive: True
        super_res_training: False
        MotionEncoder:
            learn_diff_image: True
            image_size: [64, 512]  # Non-square: 64 height x 512 width
            in_channels: 1  # Grayscale input
            model_channels: 64
            n_downs: 2
        DiffUnet:
            n_layers: 2
            nonlinear: 'tanh'
        Int:
            sde: True
            method: 'euler_heun'
            sde_options:
                noise_type: 'diagonal'
                sde_type: "stratonovich" #"Stratonovich"
                dt: 0.1
                rtol: 1e-3
                atol: 1e-3
                adaptive: False
            ode_options:
                step_size: 0.1
                norm: null

Training:
    use_ema: True
    ema_inv_gamma: 1.0
    ema_power: 0.75
    ema_max_decay: 0.9999

    learning_rate: 1e-4
    lr_scheduler: 'cosine_with_restarts'
    lr_warmup_steps: 500
    num_cycles: 2
    adam_betas: [0.95, 0.999]
    adam_weight_decay: 1e-6
    adam_epsilon: 1e-8

    epochs: 400
    save_images_epochs: 4
    save_model_epochs: 2
    checkpointing_steps: 800 #number of steps to save a resuming checkpoint
    max_checkpoints_to_keep: 3  # Automatically delete old checkpoints, keep only latest N

    gradient_accumulation_steps: 1 # Increased to maintain effective batch size
    mixed_precision: "fp16" # ["no", "fp16", "bf16"] - Use fp16 to reduce memory usage by ~50%
    gradient_checkpointing: True  # Enable to save memory at the cost of slower training
    use_xformers: True  # Enable xformers memory efficient attention (requires xformers package)

